{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from scipy.stats import norm, poisson\n",
    "from datetime import datetime, timedelta\n",
    "import random"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Date range\n",
    "start_date = datetime(2020, 1, 1)\n",
    "end_date = datetime(2023, 12, 31)\n",
    "\n",
    "# Product categories\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from datetime import datetime, timedelta\n",
    "\n",
    "# Categories and their associated product names with realistic price ranges in Indian Rupees (₹)\n",
    "categories = {\n",
    "    'Beverages': [\n",
    "        ('Coca-Cola', 40), ('Pepsi', 40), ('Sprite', 40),\n",
    "        ('Orange Juice', 80), ('Apple Juice', 80), ('Milkshake', 120),\n",
    "        ('Bottled Water', 20), ('Energy Drink', 100), ('Iced Coffee', 150),\n",
    "        ('Green Tea', 60), ('Lemonade', 70)\n",
    "    ],\n",
    "    'Snacks': [\n",
    "        ('Potato Chips', 20), ('Corn Chips', 20), ('Popcorn', 50),\n",
    "        ('Chocolate Bar', 50), ('Cookies', 60), ('Crackers', 40),\n",
    "        ('Granola Bar', 30), ('Pretzels', 40), ('Nuts Mix', 150),\n",
    "        ('Candy Pack', 20), ('Cheese Puffs', 30)\n",
    "    ],\n",
    "    'Dairy': [\n",
    "        ('Milk', 50), ('Cheese Block', 200), ('Yogurt', 60),\n",
    "        ('Butter', 80), ('Sour Cream', 90), ('Cream Cheese', 150),\n",
    "        ('Whipped Cream', 120), ('Ice Cream', 200), ('Eggs', 70),\n",
    "        ('Almond Milk', 100), ('Greek Yogurt', 120)\n",
    "    ],\n",
    "    'Personal Care': [\n",
    "        ('Shampoo', 150), ('Conditioner', 150), ('Body Wash', 120),\n",
    "        ('Toothpaste', 80), ('Deodorant', 100), ('Face Wash', 200),\n",
    "        ('Moisturizer', 300), ('Soap Bar', 30), ('Hair Gel', 120),\n",
    "        ('Sunscreen', 400), ('Razors', 250)\n",
    "    ],\n",
    "    'Household': [\n",
    "        ('Dish Soap', 50), ('Laundry Detergent', 300), ('All-Purpose Cleaner', 100),\n",
    "        ('Paper Towels', 200), ('Trash Bags', 250), ('Sponges', 40),\n",
    "        ('Air Freshener', 150), ('Bleach', 60), ('Fabric Softener', 200),\n",
    "        ('Glass Cleaner', 80), ('Disinfectant Wipes', 150)\n",
    "    ]\n",
    "}\n",
    "\n",
    "# Date range\n",
    "start_date = datetime(2020, 1, 1)\n",
    "end_date = datetime(2023, 12, 31)\n",
    "\n",
    "# Random seed for reproducibility\n",
    "np.random.seed(42)\n",
    "\n",
    "# locations\n",
    "locations = ['New York', 'Los Angeles', 'Chicago', 'Houston', 'Phoenix']\n",
    "\n",
    "\n",
    "# Customer age groups\n",
    "age_groups = ['18-25', '26-35', '36-45', '46-55', '56+']\n",
    "\n",
    "# Gender options\n",
    "genders = ['M', 'F', 'Other']\n",
    "\n",
    "# Social sentiment range\n",
    "sentiment_range = (-1, 1)\n",
    "\n",
    "# Economic indicators (example ranges)\n",
    "cpi_range = (100, 200)\n",
    "unemployment_rate_range = (3, 10)\n",
    "interest_rate_range = (0, 10)\n",
    "gdp_growth_range = (-5, 5)\n",
    "\n",
    "np.random.seed(42)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### products.csv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  product_id   category  product_name  price launch_date\n",
      "0     P00001  Beverages     Coca-Cola  39.00  2022-05-10\n",
      "1     P00002  Beverages         Pepsi  37.47  2022-12-31\n",
      "2     P00003  Beverages        Sprite  40.79  2020-05-01\n",
      "3     P00004  Beverages  Orange Juice  74.50  2020-11-26\n",
      "4     P00005  Beverages   Apple Juice  79.35  2023-10-28\n"
     ]
    }
   ],
   "source": [
    "# Generate products data\n",
    "product_data = []\n",
    "product_id_counter = 1\n",
    "\n",
    "for category, products in categories.items():\n",
    "    for product_name, base_price in products:\n",
    "        # Add some variability to the price (±10%)\n",
    "        price = round(base_price * np.random.uniform(0.9, 1.1), 2)\n",
    "        \n",
    "        # Random launch date within the date range\n",
    "        launch_date = (start_date + timedelta(days=np.random.randint(0, (end_date - start_date).days))).strftime('%Y-%m-%d')\n",
    "        \n",
    "        # Append product details\n",
    "        product_data.append({\n",
    "            'product_id': f'P{product_id_counter:05}',\n",
    "            'category': category,\n",
    "            'product_name': product_name,\n",
    "            'price': price,  # Price in Indian Rupees\n",
    "            'launch_date': launch_date\n",
    "        })\n",
    "        product_id_counter += 1\n",
    "\n",
    "# Convert to DataFrame\n",
    "products_df = pd.DataFrame(product_data)\n",
    "\n",
    "# Save to CSV\n",
    "products_df.to_csv('products.csv', index=False)\n",
    "\n",
    "# Display the first few rows\n",
    "print(products_df.head())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### sales_data.csv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    sale_id        date product_id  units_sold  revenue store_id region  \\\n",
      "0  S0000001  2020-01-01     P00001          76   190.00    STN01  North   \n",
      "1  S0000002  2020-01-01     P00002          74   355.20    STN01  North   \n",
      "2  S0000003  2020-01-01     P00003          39   153.27    STN01  North   \n",
      "3  S0000004  2020-01-01     P00004          54   183.06    STN01  North   \n",
      "4  S0000005  2020-01-01     P00005          54    87.48    STN01  North   \n",
      "\n",
      "   discount_applied  \n",
      "0               0.0  \n",
      "1               0.0  \n",
      "2               0.0  \n",
      "3               0.0  \n",
      "4               0.0  \n"
     ]
    }
   ],
   "source": [
    "# Product categories\n",
    "categories = ['Beverages', 'Snacks', 'Dairy', 'Personal Care', 'Household']\n",
    "\n",
    "# locations\n",
    "locations = ['New York', 'Los Angeles', 'Chicago', 'Houston', 'Phoenix']\n",
    "\n",
    "\n",
    "# Date range\n",
    "start_date = datetime(2020, 1, 1)\n",
    "end_date = datetime(2023, 12, 31)\n",
    "\n",
    "# Seasonality factors (monthly multipliers for each category)\n",
    "seasonality_factors = {\n",
    "    'Beverages': [1.2, 1.1, 1.0, 0.9, 0.8, 0.7, 0.8, 0.9, 1.0, 1.1, 1.2, 1.3],  # Higher in summer\n",
    "    'Snacks': [1.0, 1.0, 1.1, 1.2, 1.3, 1.4, 1.5, 1.6, 1.4, 1.2, 1.1, 1.0],     # Peak during holidays\n",
    "    'Dairy': [1.0, 1.1, 1.2, 1.0, 0.9, 0.8, 0.9, 1.0, 1.2, 1.3, 1.4, 1.5],       # Higher in winter\n",
    "    'Personal Care': [1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0],  # Consistent demand\n",
    "    'Household': [1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0]   # Consistent demand\n",
    "}\n",
    "\n",
    "# Base revenue growth rate (trend)\n",
    "base_growth_rate = 0.001  # 0.1% daily growth\n",
    "\n",
    "# Number of stores per region\n",
    "num_stores_per_region = 5\n",
    "\n",
    "# Price ranges for each category\n",
    "price_ranges = {\n",
    "    'Beverages': (1.0, 5.0),\n",
    "    'Snacks': (0.5, 3.0),\n",
    "    'Dairy': (2.0, 10.0),\n",
    "    'Personal Care': (5.0, 20.0),\n",
    "    'Household': (10.0, 50.0)\n",
    "}\n",
    "def generate_sales_data(num_products_per_category=10):\n",
    "    sales_data = []\n",
    "    sale_id_counter = 1\n",
    "    current_date = start_date\n",
    "\n",
    "    # Generate product IDs and prices\n",
    "    products = []\n",
    "    product_id_counter = 1\n",
    "    for category in categories:\n",
    "        for _ in range(num_products_per_category):\n",
    "            price = round(np.random.uniform(*price_ranges[category]), 2)\n",
    "            products.append({\n",
    "                'product_id': f'P{product_id_counter:05}',\n",
    "                'category': category,\n",
    "                'price': price\n",
    "            })\n",
    "            product_id_counter += 1\n",
    "\n",
    "    # Generate sales data\n",
    "    while current_date <= end_date:\n",
    "        for region in locations:\n",
    "            for store_num in range(1, num_stores_per_region + 1):\n",
    "                store_id = f'ST{region[0]}{store_num:02}'  # Example: SN01 for North Store 1\n",
    "                for product in products:\n",
    "                    # Seasonality and trend factors\n",
    "                    month = current_date.month - 1\n",
    "                    seasonality = seasonality_factors[product['category']][month]\n",
    "                    trend = 1 + base_growth_rate * (current_date - start_date).days\n",
    "                    base_units_sold = int(np.random.poisson(lam=50))  # Poisson distribution for units sold\n",
    "                    units_sold = int(base_units_sold * seasonality * trend)\n",
    "\n",
    "                    # Random discount (10% chance of promotion)\n",
    "                    discount = round(np.random.uniform(0, 0.3), 2) if np.random.rand() < 0.1 else 0\n",
    "                    revenue = units_sold * product['price'] * (1 - discount)\n",
    "\n",
    "                    # Append record\n",
    "                    sales_data.append({\n",
    "                        'sale_id': f'S{sale_id_counter:07}',\n",
    "                        'date': current_date.strftime('%Y-%m-%d'),\n",
    "                        'product_id': product['product_id'],\n",
    "                        'units_sold': units_sold,\n",
    "                        'revenue': round(revenue, 2),\n",
    "                        'store_id': store_id,\n",
    "                        'region': region,\n",
    "                        'discount_applied': discount\n",
    "                    })\n",
    "                    sale_id_counter += 1\n",
    "\n",
    "        current_date += timedelta(days=1)\n",
    "\n",
    "    return pd.DataFrame(sales_data)\n",
    "\n",
    "# Generate sales data\n",
    "sales_df = generate_sales_data()\n",
    "\n",
    "# Save to CSV\n",
    "sales_df.to_csv('fmcg_sales_data.csv', index=False)\n",
    "\n",
    "# Display the first few rows\n",
    "print(sales_df.head())\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### economic_indicators.csv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "         date       region     cpi  unemployment_rate  interest_rate  \\\n",
      "0  2020-01-01     New York  198.76               3.43           4.62   \n",
      "1  2020-01-01  Los Angeles  227.28               7.63           8.27   \n",
      "2  2020-01-01      Chicago  149.86               3.48           5.41   \n",
      "3  2020-01-01      Houston  132.24               8.35           6.69   \n",
      "4  2020-01-01      Phoenix  274.29               9.46           6.14   \n",
      "\n",
      "   gdp_growth  \n",
      "0        2.73  \n",
      "1       -0.28  \n",
      "2        1.06  \n",
      "3        9.61  \n",
      "4        8.02  \n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from datetime import datetime, timedelta\n",
    "\n",
    "# Parameters\n",
    "start_date = datetime(2020, 1, 1)\n",
    "end_date = datetime(2023, 12, 31)\n",
    "\n",
    "# Realistic ranges for economic indicators\n",
    "cpi_range = (100, 300)  # Base CPI range\n",
    "unemployment_rate_range = (3, 12)  # Percentage\n",
    "interest_rate_range = (4, 8)  # Percentage\n",
    "gdp_growth_range = (-5, 10)  # Percentage\n",
    "\n",
    "# Correlation multipliers (to simulate relationships between indicators)\n",
    "inflation_impact_on_interest_rate = 0.5  # Higher CPI increases interest rates\n",
    "gdp_impact_on_unemployment = -0.2  # Higher GDP growth reduces unemployment\n",
    "\n",
    "# Generate economic data\n",
    "economic_data = []\n",
    "current_date = start_date\n",
    "\n",
    "while current_date <= end_date:\n",
    "    for region in locations:\n",
    "        # Simulate gradual trends over time\n",
    "        months_since_start = (current_date.year - start_date.year) * 12 + (current_date.month - start_date.month)\n",
    "        trend_factor = 1 + (months_since_start / 12) * 0.05  # 5% annual growth trend\n",
    "        \n",
    "        # Generate base economic indicators\n",
    "        cpi = round(np.random.uniform(cpi_range[0], cpi_range[1]) * trend_factor, 2)\n",
    "        gdp_growth = round(np.random.uniform(gdp_growth_range[0], gdp_growth_range[1]) * (1 + np.random.normal(0, 0.1)), 2)\n",
    "        unemployment_rate = round(np.random.uniform(unemployment_rate_range[0], unemployment_rate_range[1]) + gdp_growth * gdp_impact_on_unemployment, 2)\n",
    "        interest_rate = round(np.random.uniform(interest_rate_range[0], interest_rate_range[1]) + (cpi - cpi_range[0]) * inflation_impact_on_interest_rate / 100, 2)\n",
    "        \n",
    "        # Ensure no unrealistic values\n",
    "        unemployment_rate = max(0, min(100, unemployment_rate))  # Unemployment between 0% and 100%\n",
    "        gdp_growth = max(-10, min(20, gdp_growth))  # GDP growth between -10% and 20%\n",
    "        \n",
    "        # Append record\n",
    "        economic_data.append({\n",
    "            'date': current_date.strftime('%Y-%m-%d'),\n",
    "            'region': region,\n",
    "            'cpi': cpi,\n",
    "            'unemployment_rate': unemployment_rate,\n",
    "            'interest_rate': interest_rate,\n",
    "            'gdp_growth': gdp_growth\n",
    "        })\n",
    "    \n",
    "    # Move to the next month\n",
    "    current_date += timedelta(days=30)\n",
    "\n",
    "# Convert to DataFrame\n",
    "economic_df = pd.DataFrame(economic_data)\n",
    "\n",
    "# Save to CSV\n",
    "economic_df.to_csv('economic_indicators.csv', index=False)\n",
    "\n",
    "# Display the first few rows\n",
    "print(economic_df.head())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### social_sentiment.csv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Generate social_sentiment.csv\n",
    "social_data = []\n",
    "current_date = start_date\n",
    "\n",
    "while current_date <= end_date:\n",
    "    for category in categories:\n",
    "        social_data.append({\n",
    "            'date': current_date.strftime('%Y-%m-%d'),\n",
    "            'category': category,\n",
    "            'avg_sentiment': round(np.random.uniform(*sentiment_range), 2),\n",
    "            'mentions': np.random.randint(100, 1000),\n",
    "            'engagements': np.random.randint(500, 5000)\n",
    "        })\n",
    "    current_date += timedelta(days=7)  # Weekly data\n",
    "\n",
    "social_df = pd.DataFrame(social_data)\n",
    "social_df.to_csv('social_sentiment.csv', index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### customer_data.csv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Generate customer_data.csv\n",
    "customer_data = []\n",
    "num_customers = 1000\n",
    "\n",
    "for i in range(num_customers):\n",
    "    signup_date = start_date + timedelta(days=np.random.randint(0, 1095))\n",
    "    churned = np.random.rand() < 0.2  # 20% churn rate\n",
    "    retention_score = round(norm.rvs(loc=0.7, scale=0.1), 2) if not churned else round(norm.rvs(loc=0.3, scale=0.1), 2)\n",
    "\n",
    "    customer_data.append({\n",
    "        'customer_id': f'C{i+1:05}',\n",
    "        'signup_date': signup_date.strftime('%Y-%m-%d'),\n",
    "        'region': random.choice(locations),\n",
    "        'age_group': random.choice(age_groups),\n",
    "        'gender': random.choice(genders),\n",
    "        'retention_score': max(0, min(1, retention_score)),  # Clamp between 0 and 1\n",
    "        'is_churned': churned\n",
    "    })\n",
    "\n",
    "customer_df = pd.DataFrame(customer_data)\n",
    "customer_df.to_csv('customer_data.csv', index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### customer_purchases.csv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Generate customer_purchases.csv\n",
    "purchase_data = []\n",
    "purchase_id_counter = 1\n",
    "\n",
    "for _, customer in customer_df.iterrows():\n",
    "    num_purchases = np.random.randint(1, 20)  # Random number of purchases per customer\n",
    "    for _ in range(num_purchases):\n",
    "        product = products_df.iloc[np.random.randint(0, len(products_df))]\n",
    "        purchase_date = datetime.strptime(customer['signup_date'], '%Y-%m-%d') + timedelta(days=np.random.randint(0, 1000))\n",
    "        quantity = np.random.randint(1, 5)\n",
    "        total_price = round(quantity * product['price'] * (1 - np.random.uniform(0, 0.2)), 2)  # Apply random discount\n",
    "\n",
    "        purchase_data.append({\n",
    "            'purchase_id': f'PU{purchase_id_counter:07}',\n",
    "            'customer_id': customer['customer_id'],\n",
    "            'product_id': product['product_id'],\n",
    "            'purchase_date': purchase_date.strftime('%Y-%m-%d'),\n",
    "            'quantity': quantity,\n",
    "            'total_price': total_price\n",
    "        })\n",
    "        purchase_id_counter += 1\n",
    "\n",
    "purchase_df = pd.DataFrame(purchase_data)\n",
    "purchase_df.to_csv('customer_purchases.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from datetime import datetime, timedelta\n",
    "import random\n",
    "from faker import Faker\n",
    "from textblob import TextBlob"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Parameters\n",
    "np.random.seed(42)  # For reproducibility\n",
    "fake = Faker()\n",
    "\n",
    "# Product categories\n",
    "categories = ['Beverages', 'Snacks', 'Dairy', 'Personal Care', 'Household']\n",
    "\n",
    "# Locations\n",
    "locations = ['New York', 'Los Angeles', 'Chicago', 'Houston', 'Phoenix']\n",
    "\n",
    "# Date range\n",
    "start_date = datetime(2020, 1, 1)\n",
    "end_date = datetime(2023, 12, 31)\n",
    "\n",
    "# Review templates\n",
    "positive_templates = [\n",
    "    \"I absolutely love this product! It's worth every penny.\",\n",
    "    \"Great quality and fast delivery. Highly recommend!\",\n",
    "    \"This is my go-to brand for {category}. Never disappoints.\",\n",
    "    \"Perfect for daily use. Couldn't be happier with my purchase.\"\n",
    "]\n",
    "\n",
    "negative_templates = [\n",
    "    \"Very disappointed with this product. It broke after one use.\",\n",
    "    \"The quality is terrible. Would not recommend.\",\n",
    "    \"Not what I expected. Feels cheap and overpriced.\",\n",
    "    \"Delivery was late, and the item was damaged.\"\n",
    "]\n",
    "\n",
    "neutral_templates = [\n",
    "    \"It's okay, nothing special.\",\n",
    "    \"Does the job, but there are better options out there.\",\n",
    "    \"Average product, neither good nor bad.\",\n",
    "    \"Decent quality, but could improve.\"\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_reviews(num_reviews=1000):\n",
    "    reviews = []\n",
    "    review_id_counter = 1\n",
    "\n",
    "    for _ in range(num_reviews):\n",
    "        # Randomly select metadata\n",
    "        product_id = f'P{random.randint(1, 100):05}'\n",
    "        customer_id = f'C{random.randint(1, 500):05}'\n",
    "        category = random.choice(categories)\n",
    "        location = random.choice(locations)\n",
    "        timestamp = fake.date_time_between(start_date=start_date, end_date=end_date)\n",
    "\n",
    "        # Randomly assign a rating\n",
    "        rating = random.randint(1, 5)\n",
    "\n",
    "        # Select a review template based on rating\n",
    "        if rating >= 4:\n",
    "            template = random.choice(positive_templates)\n",
    "            sentiment_score = 1  # Positive\n",
    "        elif rating == 3:\n",
    "            template = random.choice(neutral_templates)\n",
    "            sentiment_score = 0  # Neutral\n",
    "        else:\n",
    "            template = random.choice(negative_templates)\n",
    "            sentiment_score = -1  # Negative\n",
    "\n",
    "        # Personalize the review text\n",
    "        review_text = template.format(category=category)\n",
    "\n",
    "        # Append review data\n",
    "        reviews.append({\n",
    "            'review_id': f'R{review_id_counter:07}',\n",
    "            'product_id': product_id,\n",
    "            'customer_id': customer_id,\n",
    "            'category': category,\n",
    "            'rating': rating,\n",
    "            'review_text': review_text,\n",
    "            'sentiment_score': sentiment_score,\n",
    "            'timestamp': timestamp.strftime('%Y-%m-%d %H:%M:%S'),\n",
    "            'location': location\n",
    "        })\n",
    "\n",
    "        review_id_counter += 1\n",
    "\n",
    "    return pd.DataFrame(reviews)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  review_id product_id customer_id   category  rating  \\\n",
      "0  R0000001     P00098      C00002      Dairy       4   \n",
      "1  R0000002     P00050      C00352  Household       1   \n",
      "2  R0000003     P00095      C00191  Household       2   \n",
      "3  R0000004     P00061      C00439     Snacks       5   \n",
      "4  R0000005     P00075      C00043  Beverages       4   \n",
      "\n",
      "                                         review_text  sentiment_score  \\\n",
      "0  Perfect for daily use. Couldn't be happier wit...                1   \n",
      "1       Delivery was late, and the item was damaged.               -1   \n",
      "2      The quality is terrible. Would not recommend.               -1   \n",
      "3  Perfect for daily use. Couldn't be happier wit...                1   \n",
      "4  I absolutely love this product! It's worth eve...                1   \n",
      "\n",
      "             timestamp     location  \n",
      "0  2023-04-17 06:41:48  Los Angeles  \n",
      "1  2020-05-12 02:18:37     New York  \n",
      "2  2021-10-19 18:39:58     New York  \n",
      "3  2020-11-19 02:21:17     New York  \n",
      "4  2022-06-23 12:12:02      Phoenix  \n"
     ]
    }
   ],
   "source": [
    "# Generate 10,000 reviews\n",
    "reviews_df = generate_reviews(num_reviews=10000)\n",
    "\n",
    "# Save to CSV\n",
    "reviews_df.to_csv('retail_reviews.csv', index=False)\n",
    "\n",
    "# Display the first few rows\n",
    "print(reviews_df.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
